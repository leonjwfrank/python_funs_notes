# 查找
    顺序查找
        无序表的顺序查找，按下标逐个排查，到最后一个仍然没有则查找失败
    无序表和有序表的顺序查找复杂度都是 O(N), 有序表的比对次数可能会比无序表小
        O(n)
    
    二分查找
        分而治之，将若干问题缩小，适合 递归解法
        O(logn)
    ## 约化(Reducibility，有的资料上叫“归约”
        一个问题A可以约化为问题B的含义即是，可以用问题B的解法解决问题A，或者说，问题A可以“变成”问题B。
        《算法导论》上举了这么一个例子。比如说，现在有两个问题：求解一个一元一次方程和求解一个一元二次方程。
        那么我们说，前者可以约化为后者，意即知道如何解一个一元二次方程那么一定能解出一元一次方程
         “问题A可约化为问题B”有一个重要的直观意义：B的时间复杂度高于或者等于A的时间复杂度。也就是说，问题A不比问题B难。
         约化具有传递性。如果问题A可约化为问题B，问题B可约化为问题C，则问题A一定可约化为问题C。这个道理非常简单，就不必阐述了.
         对于程序而言，如果能找到一个变化法则，对任意一个程序A对输入，都能按这个法则变换成程序B的输入，使两程序输出相同，那么我们说问题A可以约化为问题B.
         我们所说的“可约化”是指的可“多项式地”约化(Polynomial-time Reducible)，即变换输入的方法是能在多项式的时间里完成的。约化的过程只有用多项式的时间完成才有意义.
                
    ## 多项式时间和归约问题
    P/NP/NPC/NP-hard问题
    P: 能在多项式时间内解决的问题
    NP: 不能在多项式时间内解决或不确定能不能在多项式时间内解决，但能在多项式时间验证的问题
        NP问题就是指其解的正确性可以在多项式时间内被检查的一类问题。比如说数组求和，得到一个解，这个解对不对呢，显然是可以在多项式时间内验证的。
    NPC: NP完全问题，所有NP问题在多项式时间内都能约化(Reducibility)到它的NP问题，即解决了此NPC问题，所有NP问题也都得到解决。 
        如旅行商问题，如果有10个城市需要到访，找出其中最短路径，那么需要计算 10! 个路径并选择最短的。
        集合覆盖问题也是NP完成问题。 
    NPC问题的定义非常简单。同时满足下面两个条件的问题就是NPC问题。
          首先，它得是一个NP问题；
          然后，所有的NP问题都可以约化到它。证明一个问题是 NPC问题也很简单。
          先证明它至少是一个NP问题，再证明其中一个已知的NPC问题能约化到它（由约化的传递性，则NPC问题定义的第二条也得以满足
    NP hard:NP难问题，所有NP问题在多项式时间内都能约化(Reducibility)到它的问题(不一定是NP问题)。
        NP-Hard问题。NP-Hard问题是这样一种问题，它满足NPC问题定义的第二条但不一定要满足第一条（就是说，NP-Hard问题要比 NPC问题的范围广
    
    信息学的问题: 有P属于NP。现在，所有对NP问题的研究都集中在一个问题上，即究竟是否有P=NP？通常所谓的“NP问题”，其实就一句话：证明或推翻P=NP
    
##    散列  Hashing
        散列表，hash table  哈希表
        散列表(hash table，又称哈希表)是一 种数据集，其中数据项的存储方式尤其有 利于将来快速的查找定位.
        * 实现从数据项到存储槽名称的转换的，称 为散列函数(hash function)
        * 负载因子

            哈希表装填因子定义为：α= 填入表中的元素个数 / 哈希表的长度
            α是哈希表装满程度的标志因子。由于表长是定值，α与“填入表中的元素个数”成正比，所以，α越大，填入表中的元素较多，产生冲突的可能性就越大；α越小，填入表中的元素较少，产生冲突的可能性就越小
            例:一个11个槽位的hash表，将装入6个数据元素，那么负载因子就是 6/11=0.55
            
            散列表中的每一个存储位置，称为槽( slot)，可以用来保存数据项，每个槽有 一个唯一的名称
        
        由数据项的值来确定其存放位置
        
        是一种数据集，其中数据项存储方式尤其有利于将来快速查找定位
        O(1)
        能够使得查找的次数降低到常数级别，我 们对数据项所处的位置就必须有更多的先 验知识
        事先能知道要找的数据项应该出 现在数据集中的什么位置，就可以直接到 那个位置看看数据项是否存在即可。
        * 由数据项的值来确定其存放位置，如何能 做到这一点呢?
        
        例: 一个包含11个槽的散列表，槽的名 称分别为0~10
        
        * 构造方法:
        1。取余法:
        取关键字被不大于哈希表长m的某个树p出后的余数为哈希地址 的方法
                    H(key) = key MOD p (p<=m)  p取为质数或不含小于20质因子的合数
                    序列:[27,17,9,19,16,43,53,8,63]
                         3   1 1  3  0  3  5  0 7
                    H(key) = key MOD 8 + 链地址冲突法
                     16 17 9 27 19 43 53 8  63
                     0  1  2 3  4  5  6  7  8  9  10  11
                    所以如果要查找到 43，原余数位为3号，但是实际需要匹配27，19，43 共3次
         
         
         
        2。折叠法
            折叠法设计散列函数的基本步骤是
            将数据项按照位数分为若干段，再将几段数字相加，最后对散列表大小求余，得到散列值
            *有时候折叠法还会包括一个隔数反转的步 骤,比如(62、76、72、55)隔数反转为(62、67 、72、55),再累加(62+67+72+55=256),对11求余(256%11=3)，所以h'(62767255)=3
             这个步骤确实为折叠法得到散列函数提供 了一种微调手段
            
            例:电话号码62767255,可以两位两位分为4段(62、76、72、55),相加(62+76+72+55=265),散列表包括11个槽，那么就是265%11=1
                所以h(62767255)=1
            
        3, 平方取中法
        平方取中法，首先将数据项做平方运算， 然后取平方数的中间两位，再对散列表的 大小求余
        首先44*44=1936，然后取中间的93，对散列表大小11求余，93%11=5   
        
        4， 非数项
        我们也可以对非数字的数据项进行散列， 把字符串中的每个字符看作ASCII码即可
        如cat，ord('c')==99, ord('a')==96, ord('t')==116
        再将这些整数累加，对散列表大小求余， 99+96+116 = 312， 312 % 11  = 4
        
            def hash_mat(astring,tablesize):
                sum = 0
                for p in range(len(astring)):
                    sum += ord(astring[p])
                return sum%tablesize
            缺点: 散列函数对所有的变位词都 返回相同的散列值
                解决，为了防止这一点，可以将字符串所在的位置作为 权重因子，乘以ord值
        散列函数设计原则: 散列函数 不能成为存储过程和查找过程的计算负担 
        如果散列函数设计太过复杂，去花费大量 的计算资源计算槽号 可能还不如简单地进行顺序查找或者二分查找       
            
        * 完美散列函数
        如果一个散列函数能把 每个数据项映射到不同的槽中，那么这个散列函数就可以称为“完美散列函数” 对于固定的一组数据，总是能想办法设计出完美 散列函数
        如果数据项经常性的变动，很难有一个系统性的方法来设计对应的完美散列函数
        好的散列算法:冲突最少(近似完美)、计算难度低(额外开销 小)、充分分散数据项(节约空间)
        
        压缩性:任意长度的数据，得到的“指纹”长度是固定的;
        易计算性:从原数据计算“指纹”很容易;(从指纹计算原数据是不可能的);
        抗修改性:对原数据的微小变动，都会引起“指纹”的大改变;
        抗冲突性:已知原数据和“指纹”，要找到相同指纹的数据(伪造)是非常困难的
        
        * 散列冲突解决
        完美散列函数的一种方法是扩大散列 表的容量，大到所有可能出现的数据项都 能够占据不同的槽
        类似于无限旅馆问题: 奇偶,同构 2**n 奇数来插入不同位置
            如果两个数据项被散列映射到同一个槽， 需要一个系统化的方法在散列表中保存第 二个数据项，这个过程称为“解决冲突”
            冲突解决方法1:为冲突的数据项 再找一个开放的空槽来保存
                最简单的就是从冲突的槽开始往后扫描，直到碰到一个空槽如果到散列表尾部还未找到，则从首部接着扫描
                寻找空槽的技术称为“开放定址 open addressing"
                向后逐个槽寻找的方法则是开放定址技术 中的“线性探测linear probing”
                h(44)=0，但发现0#槽已被77占据，向后找到第 一个空槽1#，保存
                h(55)=0，同样0#槽已经被占据，向后找到第一 个空槽2#，保存
                h(20)== 9，发现9#槽已经被31占据了，向后， 再从头开始找到3#槽保存
            
            1，如果采用线性探测方法来解决散列冲突， 则散列表的查找也遵循同样的规则。
            2，如果在散列位置没有找到查找项的话，就必须向 后做顺序查找直到找到查找项，或者碰到空槽(查找失败)
        线性探测的聚集问题
            线 性 探 测 法 的 一 个 缺 点 是 有 聚 集 ( clustering)的趋势
            即如果同一个槽冲突的数据项较多的话， 这些数据项就会在槽附近聚集起来
            从而连锁式影响其它数据项的插入
            
            将线性探测扩展 ，从逐个探测改为跳跃式探测
            
            冲突解决方法2:再散列rehashing
            newhashvalue = rehash(oldhashvalue)
            对于线性探测来说，rehash(pos)= (pos+ 1)% sizeoftable
            “+3”的跳跃式探测则是:rehash(pos)= (pos+ 3)% sizeoftable
            跳跃式探测的再散列通式是:rehash(pos)= (pos+skip)% sizeoftable
            跳跃式探测中，需要注意的是skip的取值，不能被散列表大小整除，否则会产生周期，造成很多空槽永远无法探测到
            
            一个技巧是，把散列表的大小设为素数，如例子 的11
            还 可 以 将 线 性 探 测 变 为 “ 二 次 探 测 quadratic probing
            不再固定skip的值，而是逐步增加skip值 ，如1、3、5、7、9
            这样槽号就会是原散列值以平方数增加: h, h+1, h+4, h+9, h+16...
            
            冲突解决方法3:冲突解决方案:数据项链Chaining
            除了寻找空槽的开放定址技术之外，另一 种解决散列冲突的方案是将容纳单个数据 项的槽扩展为容纳数据项集合(或者对数据项链表的引用
            这样，散列表中的每个槽就可以容纳多个 数据项，如果有散列冲突发生，只需要简 单地将数据项添加到数据项集合中
            当然，随着散列冲突的增加，对 数据项的查找时间也会相应增加
            
            查找时间:
                Hash表的平均查找长度包括查找成功时的平均查找长度和查找失败时的平均查找长度。查找成功时的平均查找长度=表中每个元素查找成功时的比较次数之和/表中元素个数；
                查找不成功时的平均查找长度相当于在表中查找元素不成功时的平均比较次数，可以理解为向表中插入某个元素，该元素在每个位置都有可能，然后计算出在每个位置能够插入时需要比较的次数，再除以表长即为查找不成功时的平均查找长度。

        # 抽象数据类型“映射” ADT Map
        其中关键码key可用于查询关联的数据值data
        键值关联的方法称为“映射Map”
        ADT Map的结构是键-值关联的无序集合
        关键码具有唯一性,通过关键码可以唯一确定一个数据值
        Map():创建一个空映射，返回空映射对象;
        put(key, val):将key-val关联对加入映射中 ，如果key已存在，将val替换旧关联值;
        get(key):给定key，返回关联的数据值，如不 存在，则返回None;
        del:通过del map[key]的语句形式删除key- val关联;
        len():返回映射中key-val关联的数目;
        in:通过key in map的语句形式，返回key是否 存在于关联中，布尔值
        
        使用字典的优势在于，给定关键码key， 能够很快得到关联的数据值data
        为了达到快速查找的目标，需要一个支持 高效查找的ADT实现
        可以采用列表数据结构加顺序查找或者二分查找,当然，更为合适的是使用前述的散列表来实现， 这样查找可以达到最快O(1)的性能
        class  HashTable:
            def __init__(self_):
                self.size=11
                self.slots=[None]*self.size
                self.data=[None]*self.size
               
        * 应用  任意长度的数据生成长度固定的“指纹”，还要求具备唯一性
        完美散列函数能够对任何不同的数据 生成不同的散列值，如果把散列值当作数 据的“指纹”或者“摘要”，这种特性被 广泛应用在数据的一致性校验上
            1，由任意长度的数据生成长度固定的“指纹”，还要求具备唯一性，这在数学上是无法做到的，但设计巧妙的“准完美”散列函数却能在实用范围内做到这一点。
            2，数据文件一致性判断
            3，为每个文件计算其散列值，仅对比其散列值即可得知是否文件内容相同
            4，用于网络文件下载完整性校验;
            5，用于文件分享系统:网盘中相同的文件( 尤其是电影)可以无需存储多次。
            6，数据一致性校验
                加密形式保存密码
                仅保存密码的散列值，用户输入密码后，计算散列值并比对;
                无需保存密码的明文即可判断用户是否输 入了正确的密码
                防文件篡改:原理同数据文件一致性判断
                彩票投注应用
        
        
#### 散列应用- 区块链
        区块链由一个个区块(block)组成，区 块分为头(head)和体(body)
        特点:
        区块头记录了一些元数据和链接到前一个 区块的信息
            生成时间、前一个区块(head+body)的散列值
        区块体记录来实际数据
        
        去中心化(分布式)，共识算法，安全
        通过网络连接的节点
        区块链是一种分布式数据库
        每个节点都保存着整个数据库所有数据
        任何地点存入的数据都会完成同步
        由于散列值具有抗修改性，任何对某个区 块数据的改动必然引起散列值的变化
        
        * 工作量证明:Proof of Work(POW)
        目前最大规模区块链Bitcoin采用的速度是平均 每10分钟生成一个区块
        大家不惜付出海量的计算，去抢着算出一 个区块的有效散列值
        最先算出的那位“矿工”才有资格把区块 挂到区块链中
        
        区块很难算出
            因为很难算出，所以控制了新区块生成的 速度，便于在整个分布式网络中进行同步
            每个区块设置了一个难度系数Difficulty ，用常数targetmax除以它，得到一个 target，难度系数越高，target越小
            找到一个数值Nonce，把 它跟整个区块数据一起计算散列，这个散 列值必须小于target，才是有效的散列值
            由于散列值无法回推原值，这个Nonce的 寻找只能靠暴力穷举，计算工作量+运气 是唯一的方法
            硬件摩尔定律，挖矿计算力升级:CPU(20MHash/s)→GPU( 400MHash/s)→FPGA(25GHash/s)→ASIC( 3.5THash/s)→大规模集群挖矿( 3.5THash/s*X)
            
        在加密货币Bitcoin中，区块内包含的数 据是“交易记录”，也就是“账本”，这 对于货币体系至关重要
        Bitcoin规定，每个区块中包含了一定数 量的比特币作为“记账奖励”，这样就鼓 励了更多人加入到抢先记账的行列
        
        举例:完美散列函数是MD5和 SHA系列函数
        MD5:Message Digest)将任何长度的数据变换为固定长为128位(16字节)的“摘要”
            128位二进制已经是一个极为巨大的数字空间: 据说是地球沙粒的数量
        SHA(Secure Hash Algorithm)是另 一组散列函数
            SHA-0/SHA-1输出散列值160位(20字节)
            SHA-256/SHA-224分别输出256位、224位，
            SHA-512/SHA-384分别输出512位和384位
            160位二进制相当于10的48次方，地球上 水分子数量估计是47次方
            256位二进制相当于10的77方，已知宇宙 所有基本粒子大约是72~87次方
        * python 库 hashlib
            包括了md5 / sha1 / sha224 / sha256 / sha384 / sha512等6种散列函数
            hashlib.md5("hello").hexdigest()
            hashlib.sha1('hello').hexdigest()
            
            除了对单个字符串进行散列计算之外，还可以用update方法来对任意长的数据分部分来计算
            这样不管多大的数据都不会有内存不足的 问题
    
# 排序
    代码 structure/base_code/searchPolicy
    冒泡排序 Bubble sort
        每一趟把最大的放到最后
        冒泡排序性能优化，不能降低计算复杂度
        
        最差O(n**2)
    选择排序
        冒泡排序的优化
        O(N)
    插入排序
        O(N**2)
        [17,26,54,77,93,31,44,55,20]
        取出待排序数 31
        [17,26,54,77,None,93,44,55,20]  # 93 大于31 所以向右移动一位
        [17,26,54,None,77,93,44,55,20]  # 77也大于31，所以77向右移动一位
        [17,26,None,54,77,93,44,55,20]  # 54也大于31，所以54向右移动一位
        [17,26,31,54,77,93,44,55,20]    # 26小于 31，所以插入31在26右边，54的左边
        
        比对次数最多 O(N)
        列表越接近有序，比对次数越少
    谢尔排序 Shell sort
        插入排序的优化，
        先对子列表排序
        子列表的间隔一般从n/2开始，每趟倍增: n/4,n/8,...直到1
    归并排序 
    
        子列表排序，然后合并子列表
        分裂 和 归并
        时间复杂度
        分裂:借鉴二分查找的复杂度 O(logn) 
        归并: 对于分裂的每个部分，其所有数据项都会被比较和放置一次，所以是线性复杂度。时间复杂度O(N)
        每次分裂的部分都进行一次O(n)的数
        根据归并，总的时间复杂度是 O(nlogn)   
        如果有巨大的数据，归并的存储空间需要考虑
    快速排序 Quick Sort
        递归算法实现，分裂和移动
        随机选择一个数作为"中位数"
        分裂列表为两部分，左标向右移动，右标向左移动
        复杂度 O(nlogn),没有额外的空间复杂度
            极端情况加上递归调用 ,最糟糕时如果中值选择不合适，可能比冒泡还差 O(n**2)
        中值选取方法(头，尾，中部选择3个点，三点取样)，采样方法
        
        
# 树
    数的概念
        略
    术语
        BST搜索树
        树的左子节点都小于根节点，而右子节点都大于根
        AVL搜索树
        平衡二叉搜索树
        
        最小堆 最小的元素在头部
        最大堆 最大的元素在头部
    
    树的嵌套列表实现
        第1个元素为根节点的值;
        第2个元素是左子树(所以也是一个列表); 第3个元素是右子树(所以也是一个列表)。
        [root, left, right]
        根是myTree[0]，左子树myTree[1]，右子树 myTree[2]
         
        嵌套列表法的优点 
            子树的结构与树相同，是一种递归数据结构
            很容易扩展到多叉树，仅需要增加列表元素即可
            
        嵌套实现的函数
            BinaryTree创建仅有根节点的二叉树 insertLeft/insertRight将新节点插入树中作
            为其直接的左/右子节点 get/setRootVal则取得或返回根节点 getLeft/RightChild返回左/右子树
            
    树的链表实现
        * 建立表达式解析式， 代码实践
        
        
    使用节点(node)和引用实现树
        我们第二种实现树的方式使用节点和引用。在这种情况下，我们将定义具有根值，以及左子树 和右子树属性的类。
        由于这种实现方式与面向对象的编程方式联系更紧密，我们将继续使用这种实 现方式完成本章的其余部分
    树的应用
        0，表达式求值，规则
            如果当前单词是"(":为当前节点添加一个新节 点作为其左子节点，当前节点下降为这个新节点
            如果当前单词是操作符"+,-,/,*":将当前节点 的值设为此符号，为当前节点添加一个新节点作 为其右子节点，当前节点下降为这个新节点
            如果当前单词是操作数:将当前节点的值设为此数，当前节点上升到父节点
            如果当前单词是")":则当前节点上升到父节点
            
        1，自然界动物分类
            界
                门
                    纲
                        属
                            种
        2，操作系统的文件系统
        linux
        /
            opt
            etc
            home
                pwd
                admin
        
        3，html文件格式
        html
            head
                meta
                title
            body
                ul
                    li
                    li
                h1
                h2
    * 树的遍历
        ** 代码实践
        后序遍历对表达式求值
    
    优先队列和二叉堆
        优先队列对二叉堆实现，让其时间复杂度保持在 logN，只有二叉树可以实现对数的时间复杂度。
        概念:
        * 完全二叉树(顺序二叉树)  # 608 优先队列和二叉堆
            完全二叉树的叶节点 在树的最底层或-2层
                而且叶节点都尽量靠左方。
        * 堆次序Heap Order
            任何一个节点x，其父节点p中的key均小于x中的key
            根节点是最小的
            这样，符合“堆”性质的二叉树，其中任何一条 路径，均是一个已排序数列，根节点的key最小
        * 插入 在二叉堆操作时，如果把新key插入到堆末尾，可能破坏堆的次序，所以需要有新key的上浮操作 insert
        
        * 删除 delMin()方法。最后的叶节点替换被删除节点后，有下沉操作
            下沉路径选择，如果比子节点大，那么选择较小的子节点下沉
        
    二叉堆的python实现
        buildHeap(lst)方法。从无序表生产堆，下沉法，能够将总代价控制在O(n)
        
        堆排序，复杂度O(nlogn)
    
        
## 二叉查找树(BST)和二叉平衡树(AVL)  
    * 二叉查找树  
        比父节点小的key都出现在左子树，比父节点大的key都出现在右子树
        
    Map的实现方案中，可以采用不同的数据结构和搜索算法来保存和查找
    Key，前面已经实现了两个方案
    有序表数据结构+二分搜索算法 散列表数据结构+散列及冲突解决算法
    二叉查找树，通过二叉查找树保存key， 实现key的快速搜索
    其主要操作包括以下部分
    
    Map():创建一个空映射
    put(key, val):将key-val关联对加入映射中， 如果key已经存在，则将val替换旧关联值;
    get(key):给定key，返回关联的数据值，如不 存在，则返回None;
    del:通过del map[key]的语句形式删除key- val关联;
        节点删除分几种情况，1，删除节点没有子节点；2，删除节点有一个子节点；3，被删除节点有两个子节点
            第三种情况下，如果有两个子节点，将该二叉查找子树 右侧的 最小 的子节点，作为根节点替换 当前被删的子节点即可。
            
    len():返回映射中key-val关联的数目;
    in:通过key in map的语句形式，返回key是否 存在于关联中，布尔值
    例:
        键值1，2，3，4，5，6，7的 七个元素以某种顺序插入某二叉搜索树后，发现树的根为2，这个树的高度可能是 3 或 4 或5
        
    * 平衡二叉树 AVL
        用途: 用于实现 ADT Map，字典等数据结构的底层实现。
        原则: 最小子树旋转以使其达到平衡
        名称由来，是发明者的名字缩写，G.M. Adelson-Velskii and E.M. Landis
        利用AVL树实现ADT map，与二叉查找树BST基本相同，不同之处在于二叉树的生成和维护过程。
        AVL实现过程中，需要对每个节点跟踪 "平衡因子 balance factor" 参数
        
        平衡因子是根据节点对左右子树高度来定义的，具体来讲，就是 左右子树的高度差
            banlanceFactor = height(LeftSubTree) - height(rightSubTree)
        如果平衡因子大于0，称为 '左重left-heavy'，小于零 称为 '右重right-heavy'，平衡因子等于零 称为 '平衡'
    
        * 如果一个二叉查找树每个节点的平衡因子都在-1，0，1之间，则称这个二叉查找树 为 平衡树。
        
        平衡二叉树的最多搜索次数h和规模N的关系， 时间复杂度 O(logN) 
        如何重新平衡?(有节点的平衡因子超过(-1,0,1)的范围)
        
        如果在再平衡的时候，如下图'右重'子树，单纯的左旋无法实现再平衡
        左旋后变成左重，左重再右旋，还是回到 右重
        原右重树T                T1                      又变回右重树T，无法平衡
        A(-2)    ---左旋--->       C2  ----右旋-->       A(-2)
           C(1)                 A1                           C(1)
        B(0)                      B0                     B(0)
        
        此时需要查看原 T，发现子树右子节点有 左重，即 A的右子节点C 有 子节点 B  先对右子节点 右旋，再进行 原计划的左旋，（同样右旋的时候也要检查 左子节点是否右重）
        A(-2)      --子节点C右旋-->     A(-2)            --对树左旋-->      B(0)
            C(1)                         B(-1)                        A(0)   C(0)
        B(0)                                 C(0)
        
        例:     右旋子树达到平衡,括号内为平衡因子,即当前节点 左子树深度 - 右子树的深度。
             51(-2)         --->                    51(-1)
         41(0)    71(-2)                       41(0)     81(0)
                     81(1)                           71(0)   91(0)
                        91 
# 图
    实际上树是一种具有特殊性质的图，树是极小连通图，边的数量比节点恰好少1。
    红黑树是一种低维护成本的近似平衡树，子树高度差不会超2倍。
    假设图G是有4个顶点的有向图，且不同的边不同时具有有相同的起点与终点（即：给定起点与终点，图中最多只有一条边符合条件
        
        如果G是无圈图，那么边的数量的最大可能值为6,边的数量的最大可能值为12
        1->2->3->4->5->1是一个具有5个点和5条边的，带圈的有向图
    
    对应英文中不同的意思:
    painting:用画刷画的油画
    drawing:用硬笔画的素描/线条画 picture:真实形象所反映的画，如照片等，如take picture
    image:由印象而来的画，遥感影像做image， 因是经过传感器印象而来
    figure:轮廓图的意思，某个侧面的轮廓，所 以有figure out的说法
    diagram:抽象的概念关系图，如电路图、海洋 环流图、类层次图
    chart:由数字统计来的柱状图、饼图、折线图 
    map:地图;
    plot:地图上的一小块
    graph:重在由一些基本元素构造而来的图，如 点、线段等
    
    * 术语
        顶点Vertex(也称“节点Node”) 是图的基本组成部分，顶点具有名称标识Key， 也可以携带数据项payload
        边Edge(也称“弧Arc”) 作为2个顶点之间关系的表示，边连接两个顶点; 边可以是无向或者有向的，相应的图称作“无向 图”和“有向图”
        
        权重Weight 为了表达从一个顶点到另一个顶点的“代价”， 可以给边赋权;例如公交网络中两个站点之间的 “距离”、“通行时间”和“票价”都可以作为 权重。
        
        一个图G可以定义为G=(V, E) 其中V是顶点的集合，E是边的集合，E中的每条 边e=(v, w)，v和w都是V中的顶点;
            如果是赋权图，则可以在e中添加权重分量 子图:V和E的子集
        
            赋权图的例子:6个顶点及9条边 有向赋权图，权重为整数
  
        路径Path 图中的路径，是由边依次连接起来的顶点序列;
            无权路径的长度为边的数量;带权路径的长度为
            所有边权重的和;
            如下图的一条路径(v3,v4,v0,v1)
        圈Cycle 圈是首尾顶点相同的路径，如下图中 (v5,v2,v3,v5)是一个圈
            如果有向图中不存在任何圈，则称作“有向无圈 图directed acyclic graph: DAG”
            后面我们可以看到如果一个问题能表示成DAG， 就可以用图算法很好地解决
    
        
    * 实现
    抽象数据类型ADT Graph定义如下: 
                    Graph():创建一个空的图;
                    addVertex(vert):将顶点vert加入图中 addEdge(fromVert, toVert):添加有向边
                    addEdge(fromVert, toVert, weight):添加 带权的有向边
                    getVertex(vKey):查找名称为vKey的顶点 getVertices():返回图中所有顶点列表
                    in:按照vert in graph的语句形式，返回顶点 是否存在图中True/False
    ADT Graph的实现方法有两种主要形式: 
        邻接矩阵adjacency matrix
            矩阵的每行和每列都代表图中的顶点
            如果两个顶点之间有边相连，设定行列值
            无权边则将矩阵分量标注为1，或者0 带权边则将权重保存为矩阵分量值
            
            优点:可以很容易得到顶点是如何相连
            缺点:如果图中的边数很少则效率低下 成为“稀疏sparse”矩阵
                而大多数问题所对应的图都是稀疏的 边远远少于|V|^2这个量级
        邻接表adjacency list 两种方法各有优劣，需要在不同应用中加以选择
            邻接列表adjacency list可以成为稀疏图 的更高效实现方案 维护一个包含所有顶点的主列表(master list)
            主列表中的每个顶点，再关联一个与自身有边连
            接的所有顶点的列表
            
            优点:邻接列表法的存储空间紧凑高效 很容易获得顶点所连接的所有顶点，以及连接边 的信息
        
    应用举例:
        从一个单词演变到另一个单词，其中的过 程可以经过多个中间单词
        要求是相邻两个单词之间差异只能是1个字母， 如FOOL变SAGE:
        FOOL >> POOL >> POLL >> POLE >> PALE
        >> SALE >> SAGE    
        
        目标:找到最短的单词变换序列
        将可能的单词之间的演变关系表达为图 采用“广度优先搜索 BFS”，来搜寻从开始单词
        到结束单词之间的所有有效路径
        选择其中最快到达目标单词的路径
        
        将单词作为顶点的标识Key
        如果两个单词之间仅相差1个字母，就在它们之 间设一条边
        
        改进的算法是创建大量的桶，每个桶可以 存放若干单词 桶标记是去掉1个字母，通配符“_”占空的单词
        
        所有匹配标记的单词都放到这个桶里 所有单词就位后，再在同一个桶的单词之间建立 边即可
        
        单词关系图是一个非常稀疏的图, 采用邻接表的方式。
    
        * 词梯--广度优先搜索 # 705 广度优先搜索
        在单词关系图建立完成以后，需要继续在 图中寻找词梯问题的最短序列，需要用到“广度优先搜索Breadth First Search”算法对单词关系图进行搜索
        BFS是搜索图的最简单算法之一，也是其 它一些重要的图算法的基础
        给定图G，以及开始搜索的起始顶点s BFS搜索所有从s可到达顶点的边
            而且在达到更远的距离k+1的顶点之前，BFS会 找到全部距离为k的顶点
            可以想象为以s为根，构建一棵树的过程，从顶 部向下逐步增加层次
            广度优先搜索能保证在增加层次之前，添加了所有兄弟节点到树中
        
        算法过程:
            为了跟踪顶点的加入过程，并避免重复顶 点，要为顶点增加3个属性 距离distance:从起始顶点到此顶点路径长度;
            前驱顶点predecessor:可反向追溯到起点; 
            颜色color:标识了此顶点是尚未发现(白色)、已经发现(灰色)、还是已经完成探索(黑色)
        
            还需要用一个队列Queue来对已发现的顶 点进行排列 决定下一个要探索的顶点(队首顶点)
            
            从起始顶点s开始，作为刚发现的顶点， 标注为灰色，距离为0，前驱为None， 加入队列，接下来是个循环迭代过程: 从队首取出一个顶点作为当前顶点;
            遍历当前顶点的邻接顶点，如果是尚未发现的白 色顶点，则将其颜色改为灰色(已发现)，距离 增加1，前驱顶点为当前顶点，加入到队列中
            遍历完成后，将当前顶点设置为黑色(已探索 过)，循环回到步骤1的队首取当前顶点
        
            在以FOOL为起始顶点，遍历了所有顶点 ，并为每个顶点着色、赋距离和前驱之后
            即可以通过一个回途追溯函数来确定 FOOL到任何单词顶点的最短词梯!
            
            BFS算法主体是两个循环的嵌套 while循环对每个顶点访问一次，所以是O(|V|)
                而嵌套在while中的for，由于每条边只有在其 起始顶点u出队的时候才会被检查一次
                而每个顶点最多出队1次，所以边最多被检查1次 ，一共是O(|E|)
                综合起来BFS的时间复杂度为O(|V|+|E|)
            
            词梯问题还包括两个部分算法 建立BFS树之后，回溯顶点到起始顶点的过程， 最多为O(|V|)
            创建单词关系图也需要时间，最多为O(|V|2)        
                
        * 骑士周游问题，深度优先搜索 Depth First Search  DFS
            相比广度优先搜索，其逐层建立搜索树
            深度优先是 沿着单边尽量深入，如果无法继续来仍然没有找到问题的解，则 回溯到上一层再搜索下一支。
                关键思想: 
                1，如果沿着单边深入搜索无法继续时(所有合法移动都已经被走过)，路径长度还没有达到预期值 8*8 棋盘路径预期长度为63。
                2，清除颜色标记，返回上一层。
                3，换一个分支继续深入搜索。
                
                4，回溯操作，引入一个栈来返回上一层，实现回溯。
            DFS的两个实现算法
                顶点只访问一次，用于解决骑士周游问题。
                
                顶点可以访问多次，允许顶点重复访问多次，作为其他图算法的基础。
            * 骑士周游算法改进版，Warnsdorff
                其目的是建立一个没有分支的最深的深度优先树，表现为一条线性的包含所有节点的退化树
                初始算法中nbrList，直接以原始顺序来确定优先搜索的分支次序
                Warnsdorff算法，修改了遍历下一格的次序
                    将u的合法移动目标棋盘格排序为:具有 '最少'合法移动目标的格子 '优先' 搜索。
                        
                def orderByAvail(n):
                    resList = []
                    for v in n.getConnections():
                        if v.getColor == 'white':
                            c = 0
                            for w in v.getConnections():
                                if w.getColor() == 'white':
                                    c = c+1
                            resList.append((c,v))
                    resList.sort(key=lambda x:x[0])  # 升序排序，最少的在前列。
                    return [y[1] for y in resList]
            
                使用先验经验来改进算法性能，启发式规则 heuristic
                    采用先验的知识来改进算法性能的做法， 称作为“启发式规则heuristic” 启发式规则经常用于人工智能领域;
                    可以有效地减小搜索范围、更快达到目标等等;
                    如棋类程序算法，会预先存入棋谱、布阵口诀、高手习惯等“启发式规则”，能够在最短时间内从海量的棋局落子点搜索树中定位最佳落子。
                    例如:黑白棋中的“金角银边”口诀，指导程序优先占边角位置等等。
   
# 图, 通用深度优先搜索
    一般的深度优先搜索目标是在图上进行尽量深的搜索，连接尽量多的顶点，必要时可以进行分支(创建了树)
        有时候深度优先搜索会创建多棵树，称为'深度优先森林'
    
    深度优先搜索同样要用到顶点的'前驱'属性，来构建树或森林
        另外要设置'发现时间' 和 '结束时间' 属性
        前者是在第几步访问到这个顶点(设置灰色)
        后者是在第几步完成了此顶点探索(设置黑色)
    这两个属性对后面的图算法很重要
    
    带有DFS算法的图实现为Graph的子类
    顶点Vertex增加了成员Discovery及 Finish
    图Graph增加了成员time用于记录算法执行的步骤数目
    
    * 图的应用总结
    广度优先搜索算法BFS，解决无权图的最短路径 问题(词梯问题);
    带权图最短路径的Dijkstra算法; 
    图的深度优先搜索算法DFS(骑士周游问题); 
    用于简化图的强连通分支算法; 
    用于关联任务排序的拓扑排序算法; 
    用于广播消息的最小生成树算法。
    
# 图的 拓扑排序 Topological Sort
    DAG （Directed acyclic graph）有向无环图
    在图论中，如果一个有向图无法从某个顶点出发经过若干条边回到该点，则这个图是一个有向无环图（DAG图）
    以下分别是有向树，DAG图，有向图示意图
        有向树                     DAG图            有向图
            A                      D                 T
         ↙︎    ↘︎                  ↙︎  ↘︎              ↙︎  ↘︎ 
        A1     A2               D1   D2           T1   T2
      ↙︎    ↘︎                  ↙︎   ↘︎  ↙︎          ↙︎  ↖︎︎  ↙︎
     A1f   A1r                D3   D4           T3 -> T4
     
     图中顶点的遍历方法，最小生成树就是最小代价。
     
     定义:
        从工作流程图得到工作次序排列对算法，称为 拓扑排序。
        将工作流程建立为图，工作项是节点，依赖关系是有向边
        工作流程图一定是个DAG图，否则有循环依赖。
        对DAG图调用DFS算法，以得到每个顶点的 '结束时间'
        按照每个顶点的 '结束时间'从大到小排序输出这个次序下的顶点列表。
        
     DAG图: 有向无圈图。   
     拓扑排序处理一个DAG，输出顶点的线性序列。
        使得两个顶点v,w，如果G中有(v,w)边，这线性序列中v就出现在w之前。
        对一个动作对整个过程 排成一个线性序列,拓扑排序处理一个DAG，输出顶点的线性序列，使得两个顶点v,w，如果G中有(v,w)边，在线性 序列中v就出现在w之前。
     
     拓扑排序广泛应用在依赖事件的排期上，项目管理，数据库优化查询，矩阵乘法的次序优化等。   
     如下拓扑
     1  2
     ↓  ↓
     3->4
     其可能的拓扑排序为: 1324, 1234, 2134 一定要保证4 最后完成。
     
    * 强连通分支
        强连通图是指一个有向图中任意两点v1、v2间存在v1到v2的路径（path）及v2到v1的路径的图。
        A <-> B
        定义为图G的一个子集C C中的任意两个顶点v,w之间都有路径来回，即 (v,w)(w,v)都是C的路径，而且C是具有这样性质的最大子集。
        
        互联网的图
        网络结构图，由主机和网线或无线网络构成，主机为顶点，网路为边
        web网络页面图，网页为顶点，网页内的超链接为边
        
        应用，找到网络图中的强连通分支，对网络各部分进行分类。
        图中发现高度聚集节点群的算法，即寻 找“强连通分支Strongly Connected Components”算法
        
        强连通分支算法：Kosaraju算法
        一个有向图G的转置GT，定义为将图G的所有边的 顶点交换次序，如将(v,w)转换为(w,v)可以观察到图和转置图在强连通分支的数量和划分上，是相同的
        1，对图G调用DFS算法，为每个顶点计算'结束时间'
        2，将图进行转置得到G^T
        3, 再对G^T调用DFS算法，但在dfs函数中，对每个顶点对搜索循环里，要以顶点对'结束时间' 倒序的顺序来搜索
        4，最后，深度优先森林中每一个棵树就是一个强连通分支。
        
        其他强连通分支算法 Tarjan， Gabow算法，百度搜索。
     
    * 最短路径问题 Dijkstra算法--internet 路由采用的其他算法
        顶点访问次序由一个优先队列来控制，队列中作为优先级的是顶点的dist属性
        最初，只有开始顶点dist设为0，而其他所有顶点dist设为 sys.maxsiz(python的最大整数)，全部加入优先队列
        随着队列中每个最低dist顶点率先出队
        计算它与邻接顶点的权重，会引起其他顶点dist的减小和修改，引起堆重排
        并据更新后的dist优先级再依次出队
        算法分析:
        首先，将所有顶点加入优先队列并建堆，时间复杂度O(|V|)
        其次，每个顶点仅出队1次，每次delMin花费O(log|V|),一共是O(|V|log|V|)
        另外，每个边关联到的顶点会做一次decreaseKey操作(O(log|V|)),一共是O(|E|log|V|)
        上面三个一起相加，数量级就是 O((|V|+|E|)log|V|)  # 线性级别的复杂度
        
    * 最小生成树 spaning tree
        最小权重生成树 minimum weight spanning tree
        生成树: 
            拥有图中所有顶点和最少数量的边，以保持连通子图。
        图G(V,E)的最小生成树T，
            定义为包含所有顶点V,以及E的无圈子图并且边权重之和最小。
        按照最小生成树的路径，不需要广播的方式来发送消息，
        信息广播只需要从A开始，沿着树的路径层次向下传播，就可以达到每个路由器，每个设备只需要处理1次消息
        同时总费用最小。
        
        算法:
        Prim算法。属于贪心算法，每步都沿着最小权重边向前搜索。
        构造最小生成树的思路很简单，如果T还不是生成树，则反复做
            找到一条最小权重的'可以安全添加'的边，将边添加到树T
            可以安全添加 的边 
                定义为一端顶点在最小生成树中，另一端不在树中的边，以便保持树的无圈特性。
        
    * 图的操作实现
        可以分为两个类来实现
        一个类(Vertex)用于处理中的顶点信息
            顶点属性，Vertex类包含了顶点信息，以及顶点连接边"""
        
            self.id = num               # 主要属性 顶点编号
            self.connectedTo = {}       # 主要属性 顶点的连接信息   
            self.color = 'white'        # 顶点颜色
            self.dist = sys.maxsize     # 该顶点默认没有目的顶点，所有设置了一个系统最大值
            self.pred = None            # 
            self.disc = 0
            self.fin = 0                # 
            顶点类的方法
                addNeighbor      # 添加邻居
                setDistance     # 设置间距
                
        一个类(Graph)用于处理顶点之间的关系 
            属性如下:
                self.vertices = {}      # 顶点信息
                self.numVertices = 0   # 顶点个数,每次添加一个顶点自增1
                self.numEdge = 0       # 边个数，每次添加一条边自增1
            方法如下
            Graph():创建一个空的图;
            addVertex(vert):将顶点vert加入图中 addEdge(fromVert, toVert):添加有向边
            addEdge(fromVert, toVert, weight):添加 带权的有向边
            getVertex(vKey):查找名称为vKey的顶点 getVertices():返回图中所有顶点列表
            in:按照vert in graph的语句形式，返回顶点 是否存在图中True/False
        
        
           